<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Chi-Hsuan  Chang | Stochastic gradient descent</title>
    <meta name="author" content="Chi-Hsuan  Chang" />
    <meta name="description" content="Day 7 - 8" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://achchg.github.io/blog/2022/Stochastic_gradient_descent/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://achchg.github.io/"><span class="font-weight-bold">Chi-Hsuan</span>   Chang</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- _layouts/post.html -->

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Stochastic gradient descent</h1>
    <p class="post-meta">September 29, 2022</p>
    <p class="post-tags">
      <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>
        ·  
        <a href="/blog/tag/review">
          <i class="fas fa-hashtag fa-sm"></i> review</a>  
          
        ·  
        <a href="/blog/category/probability">
          <i class="fas fa-tag fa-sm"></i> probability</a>  
          <a href="/blog/category/gradient">
          <i class="fas fa-tag fa-sm"></i> gradient</a>  
          

    </p>
  </header>

  <article class="post-content">
    <p>I’m reviewing the gradient descent and stochastic gradient descent again with NLP in deep learning, which are common machine learning parameter optimization methods well covered by packages these days and we normally use them hand-waving. Here, I’ll use logistic regression as my example:</p>

<h4 id="stochastic-gradient-descent">(Stochastic) Gradient descent</h4>
<p>Our often goal to develop a ML model is to make better prediction (i.e. minimize the cost of a model, \(J(\theta)\)), where \(\theta\) is a single parameter of our model here. In gradient descent, we’d:</p>
<ol>
  <li>randomly initiate a value for \(\theta\) at start</li>
  <li>use the whole sample space (or a batch of data) to calculate the cost of a model under the \(\theta\) estimation at iteration \(j\)</li>
  <li>
    <p>make the \(\theta\) estimation at the next iteration with the following algorithm (where \(\alpha\) is the learning rate): \(\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j}J(\theta)\)</p>
  </li>
  <li>repeat #3 until \(\theta_j\) is converged (\(J(\theta)\) is minimized)</li>
</ol>

<p>In stochastic gradient descent, instead, we’d repeat #1 - #3 at every single sample to approximate the gradient with single data point. This allows us to update the gradient and cost incrementally fairly quickly.</p>

<h4 id="cost-of-logistic-regression">Cost of logistic regression</h4>
<p>If considering a logistic regression model with the simpliest setup to classify a binary outcome \(y\) that follows a bernouli trial:</p>

\[\begin{align*}
y_i &amp; = \begin{cases}
      1 &amp; \text{, p}\\
      0 &amp; \text{, 1-p}
    \end{cases} \\
y_i &amp; \sim \text{Bernouli}(p)\\
\\
f(y) &amp; = p^y(1-p)^{1-y}\\
\\
L(y) &amp; = \Pi_{i=1}^n p^y_i(1-p)^{1-y_i}
\end{align*}\]

\[\begin{align*}
\text{logit}(p) &amp; = \alpha + \beta x_i \\
p_i &amp; = \frac{\exp(\alpha + \beta x_i)}{1 + \exp(\alpha + \beta x_i)}
\end{align*}\]

<p>Therefore, we can derive the log-likelihood function:</p>

\[\begin{align*}
\ell(y) &amp; = \Sigma_{i=1}^n y_i\log(p_i) + (1-y_i)\log(1-p_i)\\
&amp; = \Sigma_{i=1}^n \log(1-p_i) + y_i\log(\frac{p_i}{1-p_i})\\
&amp; = \Sigma_{i=1}^n -\log(1 + \exp(\alpha + \beta x_i)) + y_i(\alpha + \beta x_i)\\
\end{align*}\]

<p>If we use the negative average log-likelihood (cross entropy) as the cost function (J) would be:</p>

\[J = -\frac{1}{n}\Sigma_{i=1}^n y_i(\alpha + \beta x_i) + \log(1 + \exp(\alpha + \beta x_i))\]

<p>And the gradients of \(\alpha\) and \(\beta\) are:</p>

\[\begin{align*}
\frac{\partial}{\partial \alpha} &amp; = -\frac{1}{n}\Sigma_{i=1}^n y_i +\frac{\exp(\alpha + \beta x_i)}{1 + \exp(\alpha + \beta x_i)} = \frac{1}{n}\Sigma_{i=1}^n(p_i-y_i) = \frac{1}{n}\Sigma_{i=1}^n(\hat{y_i}-y_i)\\
\frac{\partial}{\partial \beta} &amp; = -\frac{1}{n}\Sigma_{i=1}^n y_ix_i +\frac{\exp(\alpha + \beta x_i) x_i}{1 + \exp(\alpha + \beta x_i)}= \frac{1}{n}\Sigma_{i=1}^n x_i(p_i-y_i) = \frac{1}{n}\Sigma_{i=1}^n x_i(\hat{y_i}-y_i)
\end{align*}\]

<p>With gradient descent, we’d optimize \(\alpha\) and \(\beta\) with the following algorithm and learning rates:</p>

\[\begin{align*}
\alpha_j &amp; := \alpha_j - \eta_1 \frac{1}{n}\Sigma_{i=1}^n(\hat{y_i}-y_i)\\
\beta_j &amp; := \beta_j - \eta_2 \frac{1}{n}\Sigma_{i=1}^nx_i(\hat{y_i}-y_i)
\end{align*}\]

<p>Pseudo code that I wrote from CS224 assignment. Here x is the parameter to be optimized and step is the learning rate:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr>
<td class="gutter gl"><pre class="lineno">1
2
3
4
</pre></td>
<td class="code"><pre> <span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">start_iter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">iterations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">-=</span> <span class="n">step</span> <span class="o">*</span> <span class="n">grad</span>
</pre></td>
</tr></tbody></table></code></pre></figure>

<p>Example notebook with above example can be found <a href="https://github.com/achchg/achchg.github.io/blob/master/jupyternb/2022-09-29-Stochastic_gradient_descent.ipynb" target="_blank" rel="noopener noreferrer">here</a>.</p>

<p>Great reference material can be found <a href="https://web.stanford.edu/~jurafsky/slp3/5.pdf" target="_blank" rel="noopener noreferrer">here</a></p>

  </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Chi-Hsuan  Chang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

